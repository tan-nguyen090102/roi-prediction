{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afdfa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import regularizers\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dd7639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regulate the base path for different environments\n",
    "if (sys.platform.startswith(\"linux\")):\n",
    "    pathNav = \"/\"\n",
    "else:\n",
    "    pathNav = \"\\\\\"\n",
    "\n",
    "idx = os.path.abspath(\"\").split(pathNav).index(\"roi-prediction\") + 1\n",
    "base_path = pathNav.join(os.path.abspath(\"\").split(pathNav)[:idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce438e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe_from_folder(parent_path, file_name):\n",
    "    return pd.read_csv(base_path + pathNav + parent_path + pathNav + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf02a0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort dataframe\n",
    "def sort_dataframe_on_column(df, target_columns, groupby_column=None):\n",
    "    if (groupby_column == None):\n",
    "        df = df.sort_values(by=target_columns, ascending=True).apply(lambda a: a[:]).reset_index()\n",
    "    else:    \n",
    "        df = df.sort_values(by=target_columns, ascending=True).groupby(groupby_column).apply(lambda a: a[:], include_groups=False).reset_index()\n",
    " \n",
    "    df = df.reset_index()\n",
    "    df.drop(\"index\", axis=1, inplace=True)\n",
    "    df.drop(\"level_0\", axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952007a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_column_with_zeros(df, target_column, desired_length):\n",
    "    df[target_column] = df[target_column].astype(str).str.zfill(desired_length)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d381622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_curves(history):\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    mae = history.history['mae']\n",
    "    val_mae = history.history['val_mae']\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "\n",
    "    # Plot Loss curves\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, loss, 'b-', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'r-', label='Validation Loss')\n",
    "    plt.title('Loss Curves')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot MAE curves\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, mae, 'b-', label='Training MAE')\n",
    "    plt.plot(epochs, val_mae, 'r-', label='Validation MAE')\n",
    "    plt.title('MAE Curves')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38b08a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_dataframe_from_folder(\"datasets_filtered\", \"preprocessed_dataset.csv\")\n",
    "df = sort_dataframe_on_column(df, [\"geoID\", \"year\"])\n",
    "df = pad_column_with_zeros(df, \"geoID\", 5)\n",
    "\n",
    "# static features only for the most recent years\n",
    "df_static = df[df[\"year\"] == 2023][[\"geoID\", \"tax_rate\", \"4g_st_pct\", \"median_income\", \"population\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d7fc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# window sequences\n",
    "time_series = [\"gdp\", \"unemployment_rate\", \"zhvi\", \"gdp_last_year\", \"unemployment_rate_last_year\"]\n",
    "static_series = [\"tax_rate\", \"4g_st_pct\", \"median_income\", \"population\"]\n",
    "target_roi_column = \"roi\"\n",
    "\n",
    "years_of_window = 5\n",
    "time_series_window = []\n",
    "static_series_window = []\n",
    "target_roi_window = []\n",
    "\n",
    "# iterate over each county\n",
    "for id, county_set in df.groupby(\"geoID\"):\n",
    "    county_set = county_set.sort_values(\"year\")\n",
    "\n",
    "    # check if the county has enough 5 years to slide window through\n",
    "    if len(county_set) < years_of_window + 1:\n",
    "        continue\n",
    "\n",
    "    # iterate through 5-years window (2014-2018), target roi in next year 2019\n",
    "    for index in range(len(county_set) - years_of_window - 1):\n",
    "        time_series_data = county_set.iloc[index:index + years_of_window][time_series].values\n",
    "        static_series_data = df_static[df_static[\"geoID\"] == id][static_series].values[0]\n",
    "\n",
    "        target_roi = county_set.iloc[index + years_of_window][target_roi_column]\n",
    "\n",
    "        # append the result as 1 window\n",
    "        time_series_window.append(time_series_data)\n",
    "        static_series_window.append(static_series_data)\n",
    "        target_roi_window.append(target_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f160f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy array for tensorflow\n",
    "x_time_series = np.array(time_series_window)\n",
    "x_static_series = np.array(static_series_window)\n",
    "y_label_series = np.array(target_roi_window)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f43c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split datasets\n",
    "x_times_series_train, x_time_series_test, x_static_series_train, x_static_series_test, y_label_series_train, y_label_series_test = train_test_split(\n",
    "    x_time_series, \n",
    "    x_static_series, \n",
    "    y_label_series, \n",
    "    test_size=0.2, \n",
    "    random_state=30\n",
    ")\n",
    "\n",
    "# get rid of the extreme tails data\n",
    "y_label_series_train = np.clip(y_label_series_train, -15, 25)\n",
    "y_label_series_test = np.clip(y_label_series_test, -15, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bd126b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal standardization for fair treatment between each dataset\n",
    "time_series_std = StandardScaler()\n",
    "num_time_series_samples, num_time_series_timesteps, num_time_series_features = x_times_series_train.shape\n",
    "num_static_series_samples, num_static_series_features = x_static_series_train.shape\n",
    "\n",
    "# flatten the dataset to 2D\n",
    "x_times_series_train_flat = x_times_series_train.reshape(-1, num_time_series_features)\n",
    "x_time_series_test_flat = x_time_series_test.reshape(-1, num_time_series_features)\n",
    "\n",
    "# Mean and Sigma for dataset on 2D and convert to 3D for LSTM\n",
    "x_times_series_train_std = time_series_std.fit_transform(x_times_series_train_flat).reshape(num_time_series_samples, num_time_series_timesteps, num_time_series_features)\n",
    "x_time_series_test_std = time_series_std.transform(x_time_series_test_flat).reshape(x_time_series_test.shape)\n",
    "\n",
    "# static series version\n",
    "static_series_std = StandardScaler()\n",
    "x_static_series_train_std = static_series_std.fit_transform(x_static_series_train)\n",
    "x_static_series_test_std = static_series_std.transform(x_static_series_test)\n",
    "\n",
    "joblib.dump(time_series_std, \"time_series_std.pkl\")\n",
    "joblib.dump(static_series_std, \"static_series_std.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7466c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_label_series_train, bins=50)\n",
    "plt.title(\"ROI Distribution (Training)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff514081",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_input = Input(shape=(years_of_window, num_time_series_features))\n",
    "lstm_layer_ouput = LSTM(128, activation=\"tanh\", dropout=0.3, return_sequences=True)(time_series_input)\n",
    "lstm = LSTM(64, activation=\"tanh\", dropout=0.2)(lstm_layer_ouput)\n",
    "\n",
    "static_series_input = Input(shape=(num_static_series_features,))\n",
    "dense = Dense(32, activation=\"relu\")(static_series_input)\n",
    "\n",
    "combined_input = Concatenate()([lstm, dense])\n",
    "output = Dense(1, activation=\"linear\")(combined_input)\n",
    "\n",
    "model = Model(inputs=[time_series_input, static_series_input], outputs=output)\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss=\"mse\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ee2d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_mae\", patience=50, restore_best_weights=True\n",
    ")\n",
    "\n",
    "results = model.fit(\n",
    "    [x_times_series_train_std, x_static_series_train_std],\n",
    "    y_label_series_train,\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    validation_data=([x_time_series_test_std, x_static_series_test_std], y_label_series_test),\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10214579",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"v1_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e32fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_curves(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
