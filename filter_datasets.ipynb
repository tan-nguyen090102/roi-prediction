{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bd0c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bfcc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regulate the base path for different environments\n",
    "if (sys.platform.startswith(\"linux\")):\n",
    "    pathNav = \"/\"\n",
    "else:\n",
    "    pathNav = \"\\\\\"\n",
    "\n",
    "idx = os.path.abspath('').split(pathNav).index(\"roi-prediction\") + 1\n",
    "base_path = pathNav.join(os.path.abspath('').split(pathNav)[:idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09780c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "states_list = [\n",
    "    \"United States *\",\n",
    "    \"Alabama\",\n",
    "    \"Alaska\",\n",
    "    \"Arizona\",\n",
    "    \"Arkansas\",\n",
    "    \"California\",\n",
    "    \"Colorado\",\n",
    "    \"Connecticut\",\n",
    "    \"Delaware\",\n",
    "    \"Florida\",\n",
    "    \"Georgia\",\n",
    "    \"Hawaii\",\n",
    "    \"Idaho\",\n",
    "    \"Illinois\",\n",
    "    \"Indiana\",\n",
    "    \"Iowa\",\n",
    "    \"Kansas\",\n",
    "    \"Kentucky\",\n",
    "    \"Louisiana\",\n",
    "    \"Maine\",\n",
    "    \"Maryland\",\n",
    "    \"Massachusetts\",\n",
    "    \"Michigan\",\n",
    "    \"Minnesota\",\n",
    "    \"Mississippi\",\n",
    "    \"Missouri\",\n",
    "    \"Montana\",\n",
    "    \"Nebraska\",\n",
    "    \"Nevada\",\n",
    "    \"New Hampshire\",\n",
    "    \"New Jersey\",\n",
    "    \"New Mexico\",\n",
    "    \"New York\",\n",
    "    \"North Carolina\",\n",
    "    \"North Dakota\",\n",
    "    \"Ohio\",\n",
    "    \"Oklahoma\",\n",
    "    \"Oregon\",\n",
    "    \"Pennsylvania\",\n",
    "    \"Rhode Island\",\n",
    "    \"South Carolina\",\n",
    "    \"South Dakota\",\n",
    "    \"Tennessee\",\n",
    "    \"Texas\",\n",
    "    \"Utah\",\n",
    "    \"Vermont\",\n",
    "    \"Virginia\",\n",
    "    \"Washington\",\n",
    "    \"West Virginia\",\n",
    "    \"Wisconsin\",\n",
    "    \"Wyoming\"\n",
    "  ]\n",
    "\n",
    "years_list = [\n",
    "    \"2001\",\n",
    "    \"2002\",\n",
    "    \"2003\",\n",
    "    \"2004\",\n",
    "    \"2005\", \n",
    "    \"2006\",\n",
    "    \"2007\",\n",
    "    \"2008\",\n",
    "    \"2009\",\n",
    "    \"2010\",\n",
    "    \"2011\",\n",
    "    \"2012\"\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ce9406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to reset the index of any dataframe if is not in sequence order\n",
    "def reset_sub_df_index(df, have_index_column=None):\n",
    "    new_df = df.copy()\n",
    "    if (have_index_column != None and have_index_column == True):\n",
    "        new_df.drop(\"index\", axis=1, inplace=True)\n",
    "        \n",
    "    new_df = new_df.reset_index()\n",
    "    new_df.drop(\"index\", axis=1, inplace=True)\n",
    "    new_df = new_df.reset_index()\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de8c813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe_from_folder(parent_path, file_name):\n",
    "    return pd.read_csv(base_path + pathNav + parent_path + pathNav + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711fdf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframe_to_folder(df, file_name, destination_path):\n",
    "    if (not os.path.exists(base_path + pathNav + destination_path)):\n",
    "        os.makedirs(base_path + pathNav + destination_path)\n",
    "\n",
    "    df.to_csv(base_path + pathNav + destination_path + pathNav + file_name, sep=',', index=False, encoding='utf-8', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86ae5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out rows that has unwanted values in a column\n",
    "def filter_unwanted_value(df, column, list_values):\n",
    "    df = df[~df[column].isin(list_values)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2bb08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join columns into dataframe\n",
    "def left_join_dataframe(df_1, df_2, columns):\n",
    "    df_1 = pd.merge(df_1, df_2, on=columns)\n",
    "\n",
    "    return df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b242220e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort dataframe\n",
    "def sort_dataframe_on_column(df, target_columns, groupby_column=None):\n",
    "    if (groupby_column == None):\n",
    "        df = df.sort_values(by=target_columns, ascending=True).apply(lambda a: a[:]).reset_index()\n",
    "    else:    \n",
    "        df = df.sort_values(by=target_columns, ascending=True).groupby(groupby_column).apply(lambda a: a[:], include_groups=False).reset_index()\n",
    "\n",
    "    df.drop(\"index\", axis=1, inplace=True)\n",
    "    df = df.reset_index()\n",
    "    df.drop(\"level_1\", axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12496d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter dataframe based on columns list and its data\n",
    "def filter_dataframe_on_column(df, target_columns, target_values):\n",
    "    mask = df[target_columns].apply(lambda x: True if tuple(x.values) == tuple(target_values) else False, axis=1)\n",
    "    return df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fb00b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter dataframe based on columns list and its data but \n",
    "def filter_dataframe_exclude_rows(df, target_columns, target_values):\n",
    "    mask = df[target_columns].apply(lambda x: tuple(x.values) != tuple(target_values), axis=1)\n",
    "    return df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f494edb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get rid of date-formatted columns with target date to cut\n",
    "def filter_columns_with_date_name_format(df, date_format=\"%Y-%m-%d\", start=\"2013-01-01\", end=\"2023-12-31\"):\n",
    "    start_date = pd.to_datetime(start)\n",
    "    end_date = pd.to_datetime(end)\n",
    "\n",
    "    filtered_cols = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        try:\n",
    "            col_date = pd.to_datetime(col, format=date_format)\n",
    "            if start_date <= col_date <= end_date:\n",
    "                filtered_cols.append(col)\n",
    "        except (ValueError, TypeError):\n",
    "            filtered_cols.append(col)\n",
    "\n",
    "    return df[filtered_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d1d771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine two columns into a new one\n",
    "def combine_columns(df, first_column, second_column, new_column_name):\n",
    "    combined_values = df[first_column].astype(str).apply(lambda x: x.zfill(2)) + df[second_column].astype(str).apply(lambda x: x.zfill(3))\n",
    "    df[new_column_name] = combined_values\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da6be93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_column_with_zeros(df, target_column, desired_length):\n",
    "    df[target_column] = df[target_column].astype(str).str.zfill(desired_length)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8713659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the dataframe with kept target columns\n",
    "def copy_dataframe_with_desired_columns(df, target_columns):\n",
    "    df_copy = df[target_columns].copy()\n",
    "    df_copy = df_copy.drop_duplicates()\n",
    "\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f445d918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the dataframe without target columns\n",
    "def copy_dataframe_without_target_columns(df, target_columns):\n",
    "    df_copy = df.drop(columns=target_columns).copy()\n",
    "    df_copy = df_copy.drop_duplicates()\n",
    "\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86625063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to rename some certain columns\n",
    "def rename_columns(df, target_columns, new_values):\n",
    "    rename_dict = dict(zip(target_columns, new_values))\n",
    "\n",
    "    return df.rename(columns=rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aef801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to split a value of a string value into left and right based on separator\n",
    "def split_string_column(df, source_column, value_separator, new_column, is_left=True):\n",
    "    if is_left:\n",
    "        df[new_column] = df[source_column].str.split(value_separator).str[0]\n",
    "    else:\n",
    "        df[new_column] = df[source_column].str.split(value_separator).str[-1]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf79ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all relevant datasets unfiltered\n",
    "    # time series\n",
    "df_unfiltered_zhvi = read_dataframe_from_folder(\"datasets\", \"county_zhvi.csv\")\n",
    "df_unfiltered_county_gdp = read_dataframe_from_folder(\"datasets\", \"CAGDP2__ALL_AREAS_2001_2023.csv\")\n",
    "df_unfiltered_unemployment_rate = read_dataframe_from_folder(\"datasets\", \"county_unemployment_2013_2023_combined.csv\")\n",
    "\n",
    "    # static\n",
    "df_unfiltered_population = read_dataframe_from_folder(\"datasets\", \"demographic_5_years_est_population_2023.csv\")\n",
    "df_unfiltered_median_income = read_dataframe_from_folder(\"datasets\", \"median_income_5_years_est_2023.csv\")\n",
    "df_unfiltered_property_tax_rate = read_dataframe_from_folder(\"datasets\", \"property_tax_rate.csv\")\n",
    "df_unfiltered_mobile_broadband = read_dataframe_from_folder(\"datasets\", \"mobile_broadband.csv\")\n",
    "\n",
    "    # mapping\n",
    "df_unfiltered_FIPS = read_dataframe_from_folder(\"datasets\", \"FIPS_code.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4604c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter on desired columns\n",
    "df_unfiltered_zhvi = copy_dataframe_without_target_columns(df_unfiltered_zhvi, [\"RegionID\", \"SizeRank\", \"RegionType\", \"StateName\", \"State\", \"Metro\"])\n",
    "df_unfiltered_zhvi = combine_columns(df_unfiltered_zhvi, \"StateCodeFIPS\", \"MunicipalCodeFIPS\", \"geoID\")\n",
    "df_unfiltered_zhvi = copy_dataframe_without_target_columns(df_unfiltered_zhvi, [\"StateCodeFIPS\", \"MunicipalCodeFIPS\"])\n",
    "\n",
    "df_unfiltered_FIPS = combine_columns(df_unfiltered_FIPS, \"StateFIPS\", \"MunicipalityFIPS\", \"geoID\")\n",
    "df_unfiltered_FIPS = copy_dataframe_without_target_columns(df_unfiltered_FIPS, [\"StateFIPS\", \"MunicipalityFIPS\", \"FIPS\"])\n",
    "\n",
    "df_unfiltered_county_gdp = copy_dataframe_without_target_columns(df_unfiltered_county_gdp, [\"Region\", \"TableName\", \"LineCode\", \"IndustryClassification\", \"Unit\"])\n",
    "df_unfiltered_county_gdp = rename_columns(df_unfiltered_county_gdp, [\"GeoFIPS\", \"GeoName\"], [\"geoID\", \"name\"])\n",
    "df_unfiltered_county_gdp = copy_dataframe_without_target_columns(df_unfiltered_county_gdp, years_list)\n",
    "\n",
    "df_unfiltered_unemployment_rate = copy_dataframe_without_target_columns(df_unfiltered_unemployment_rate, [\"series_id\"])\n",
    "df_unfiltered_unemployment_rate = rename_columns(df_unfiltered_unemployment_rate, [\"area_name\"], [\"Name\"])\n",
    "\n",
    "df_unfiltered_population = copy_dataframe_with_desired_columns(df_unfiltered_population, [\"GEO_ID\", \"NAME\", \"DP05_0001E\"])\n",
    "df_unfiltered_population = split_string_column(df_unfiltered_population, \"GEO_ID\", \"S\", \"geoID\", False)\n",
    "df_unfiltered_population = copy_dataframe_without_target_columns(df_unfiltered_population, [\"GEO_ID\"])\n",
    "df_unfiltered_population = rename_columns(df_unfiltered_population, [\"NAME\", \"DP05_0001E\"], [\"name\", \"estimate\"])\n",
    "\n",
    "df_unfiltered_median_income = copy_dataframe_with_desired_columns(df_unfiltered_median_income, [\"GEO_ID\", \"NAME\", \"S1903_C01_001E\"])\n",
    "df_unfiltered_median_income = split_string_column(df_unfiltered_median_income, \"GEO_ID\", \"S\", \"geoID\", False)\n",
    "df_unfiltered_median_income = copy_dataframe_without_target_columns(df_unfiltered_median_income, [\"GEO_ID\"])\n",
    "df_unfiltered_median_income = rename_columns(df_unfiltered_median_income, [\"NAME\", \"S1903_C01_001E\"], [\"name\", \"estimate\"])\n",
    "\n",
    "df_unfiltered_property_tax_rate = copy_dataframe_with_desired_columns(df_unfiltered_property_tax_rate, [\"geoid\", \"name\", \"effective_prop_tax_rate_23\"])\n",
    "df_unfiltered_property_tax_rate = rename_columns(df_unfiltered_property_tax_rate, [\"geoid\", \"effective_prop_tax_rate_23\"], [\"geoID\", \"tax_rate\"])\n",
    "\n",
    "df_unfiltered_mobile_broadband = copy_dataframe_without_target_columns(df_unfiltered_mobile_broadband, [\"mobilebb_3g_area_iv_pct\", \"mobilebb_4g_area_iv_pct\", \"mobilebb_5g_spd1_area_iv_pct\", \"mobilebb_5g_spd2_area_iv_pct\"])\n",
    "df_unfiltered_mobile_broadband = rename_columns(df_unfiltered_mobile_broadband, [\"geography_desc\", \"geography_id\", \"mobilebb_3g_area_st_pct\", \"mobilebb_4g_area_st_pct\", \"mobilebb_5g_spd1_area_st_pct\", \"mobilebb_5g_spd2_area_st_pct\"], [\"name\", \"geoID\", \"3g_st_pct\", \"4g_st_pct\", \"5g_spd1_st_pct\", \"5g_spd2_st_pct\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d38617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter on desired rows\n",
    "df_unfiltered_county_gdp = filter_unwanted_value(df_unfiltered_county_gdp, \"name\", states_list)\n",
    "df_unfiltered_county_gdp = filter_dataframe_on_column(df_unfiltered_county_gdp, [\"Description\"], [\"All industry total \"])\n",
    "df_unfiltered_population = filter_unwanted_value(df_unfiltered_population, \"name\", [\"Geographic Area Name\", \"United States\"])\n",
    "df_unfiltered_median_income = filter_unwanted_value(df_unfiltered_median_income, \"name\", [\"Geographic Area Name\", \"United States\"])\n",
    "df_unfiltered_unemployment_rate = left_join_dataframe(df_unfiltered_unemployment_rate, df_unfiltered_FIPS, [\"Name\"])\n",
    "df_unfiltered_mobile_broadband = filter_dataframe_on_column(df_unfiltered_mobile_broadband, [\"area_data_type\", \"geography_type\"], [\"Total\", \"County\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0611734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# last filtering\n",
    "df_county_gdp = copy_dataframe_without_target_columns(df_unfiltered_county_gdp, [\"Description\"])\n",
    "df_population = df_unfiltered_population\n",
    "df_zhvi = filter_columns_with_date_name_format(df_unfiltered_zhvi)\n",
    "df_FIPS = pad_column_with_zeros(df_unfiltered_FIPS, \"geoID\", 5)\n",
    "df_median_income = df_unfiltered_median_income\n",
    "df_unemployment_rate = copy_dataframe_without_target_columns(df_unfiltered_unemployment_rate, [\"StateName\"])\n",
    "df_property_tax_rate = pad_column_with_zeros(df_unfiltered_property_tax_rate, \"geoID\", 5)\n",
    "df_mobile_broadband = copy_dataframe_without_target_columns(df_unfiltered_mobile_broadband, [\"area_data_type\", \"geography_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3735250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to files\n",
    "write_dataframe_to_folder(df_county_gdp, \"county_gdp.csv\", \"datasets_filtered\")\n",
    "write_dataframe_to_folder(df_population, \"demographic.csv\", \"datasets_filtered\")\n",
    "write_dataframe_to_folder(df_zhvi, \"zhvi.csv\", \"datasets_filtered\")\n",
    "write_dataframe_to_folder(df_FIPS, \"FIPS_code.csv\", \"datasets_filtered\")\n",
    "write_dataframe_to_folder(df_median_income, \"median_income.csv\", \"datasets_filtered\")\n",
    "write_dataframe_to_folder(df_unemployment_rate, \"unemployment.csv\", \"datasets_filtered\")\n",
    "write_dataframe_to_folder(df_property_tax_rate, \"property_tax.csv\", \"datasets_filtered\")\n",
    "write_dataframe_to_folder(df_mobile_broadband, \"mobile_broadband.csv\", \"datasets_filtered\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
